{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9dbc821",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45e0075a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, gzip\n",
    "import numpy as np\n",
    "def get(url):\n",
    "    return np.frombuffer(gzip.decompress(requests.get(url).content), dtype=np.uint8)\n",
    "\n",
    "X_train = get(\"http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\")[0x10:].reshape((-1, 28, 28))\n",
    "y_train = get(\"http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\")[8:]\n",
    "X_test = get(\"http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\")[0x10:].reshape((-1, 28, 28))\n",
    "y_test = get(\"http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\")[8:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95054216",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1215c8700>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib.pyplot import imshow\n",
    "imshow(X_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5707cb48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c4/j059kg7n61q9x8b27zrclg8c0000gn/T/ipykernel_23057/2845450077.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  X_train_scaled = torch.tensor([np.reshape(xi/256, (-1)) for xi in X_train], dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.set_printoptions(sci_mode=False)\n",
    "# Feature Scaling\n",
    "X_train_scaled = torch.tensor([np.reshape(xi/256, (-1)) for xi in X_train], dtype=torch.float32)\n",
    "X_test_scaled = torch.tensor([np.reshape(xi/256, (-1, 28*28)) for xi in X_test], dtype=torch.float32)\n",
    "\n",
    "# One-Hot encoded targets\n",
    "y_train_one_hot = [[1 if i == l else 0 for i in range(10)] for l in y_train]\n",
    "y_test_one_hot = [[1 if i == l else 0 for i in range(10)] for l in y_test]\n",
    "\n",
    "y_train_torch = torch.tensor(y_train.copy())\n",
    "y_test_torch = torch.tensor(y_test.copy())\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "train_ds = TensorDataset(X_train_scaled, y_train_torch)\n",
    "test_ds = TensorDataset(X_test_scaled, y_test_torch)\n",
    "BS = 250\n",
    "train_dl = DataLoader(train_ds, BS, shuffle=True)\n",
    "test_dl = DataLoader(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c231cbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c4/j059kg7n61q9x8b27zrclg8c0000gn/T/ipykernel_23057/733587254.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(x.reshape((-1, 28*28)), dtype=torch.float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-144.6187, -747.2369,    0.0000, -444.3639, -228.1190, -872.8916,\n",
       "         -251.4371, -309.6400,  -35.3154, -211.1194]],\n",
       "       grad_fn=<LogSoftmaxBackward0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import model\n",
    "torch.manual_seed(0)\n",
    "model = model.conNet()\n",
    "x = X_test_scaled[0]\n",
    "x = torch.tensor(x.reshape((-1, 28*28)), dtype=torch.float32)\n",
    "model.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b1ece29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:45<00:00,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[37958.00464321 28174.55793452 20835.23336239 13189.06996632\n",
      " 10927.91092582 10541.74492016  7653.77443226  7705.5995863\n",
      "  7872.61398853  6813.36587956  6682.7491005   6118.36319236\n",
      "  6586.97446069  4808.77724284  5422.25996808  5435.59096594\n",
      "  4037.89485379  3969.9724591   3987.57027858  4753.56564979\n",
      "  4460.20466335  4626.92307852  3739.90935005  4493.60047493\n",
      "  3239.3718736   3807.04125151  3716.10580316  3516.03207387\n",
      "  3310.07019638  3218.41267347  3076.44608713  3704.17353325\n",
      "  3522.86356583  2957.99368612  3248.84679754  3546.71988751\n",
      "  3256.18778887  2805.16759532  3073.10191239  3960.63059666\n",
      "  2713.57081531  2149.4093448   3260.06168082  2649.80201098\n",
      "  2261.71237802  3282.89052789  2036.07938815  2188.07713913\n",
      "  2299.16067965  2807.71781256  2751.86225073  3444.97750806\n",
      "  2741.73061445  2809.82309167  3002.18508388  2719.32777416\n",
      "  2273.19417633  1701.89100752  2200.71921679  2014.92894697\n",
      "  1211.99437326  1647.22828831  2274.50192388  3666.55751478\n",
      "  3114.35179607  1756.08591512  2290.55005279  1865.92105816\n",
      "  1674.54423158  1843.92907469  1997.72649632  1719.08904864\n",
      "  1799.75733893  2131.34978839  2161.00073601  3080.05176505\n",
      "  1997.19899095  2020.34876689  2018.35187843  2193.5336459\n",
      "  1408.0957736   1406.58365915  1399.56546829  2604.73097353\n",
      "  3125.39344942  1433.12807017  1353.18558587  1923.79807963\n",
      "  1170.89788453  1924.33520548  1784.57360073  2070.21277049\n",
      "  2077.47993874  1726.91863187  2642.04805803  1584.10942918\n",
      "   948.6950746   1571.72830345  1363.88328952  1306.94084347]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "N_EPOCH = 100\n",
    "LR = 0.01\n",
    "loss_hist = np.zeros(N_EPOCH)\n",
    "accuracy_hist = np.zeros(N_EPOCH)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "for epoch in tqdm(range(N_EPOCH)):\n",
    "    for x_batch, y_batch in train_dl:\n",
    "        # print(pred[0], y_batch[0])\n",
    "        # imshow((x_batch[0][0]*256).reshape(28,28))\n",
    "        b_x = Variable(x_batch)\n",
    "        b_y = Variable(y_batch)\n",
    "        pred = model.forward(b_x)\n",
    "        loss = loss_fn(pred, b_y)\n",
    "        # clear gradients for this training step\n",
    "        optimizer.zero_grad()\n",
    "        # backprop, compute gradients\n",
    "        loss.backward()\n",
    "        # apply gradients\n",
    "        optimizer.step()\n",
    "        loss_hist[epoch] += loss.item()*y_batch.size()[0]\n",
    "print(loss_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4e55025b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 9.800000190734863%\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    for x, target in test_dl:\n",
    "        # b_x = Variable(x)[0]\n",
    "        b_x = x\n",
    "        pred = model.forward(b_x)\n",
    "        top_1 = torch.argmax(pred)\n",
    "        n_correct += (top_1 == target)\n",
    "    print(f'accuracy: {n_correct[0]/10_000*100}%')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a0a5145e6c304e2a9afaf5b930a2955b950bd4b81fe94f7c42930f43f42762eb"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
